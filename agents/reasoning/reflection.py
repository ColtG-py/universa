"""
Reflection System
Generates higher-level insights from observations.
Based on Stanford Generative Agents paper.
"""

from typing import Optional, List, Dict, Any, Callable
from datetime import datetime, timedelta
from uuid import UUID
import re

from agents.memory.memory_stream import MemoryStream
from agents.models.memory import Memory, Reflection
from agents.config import MemoryType, REFLECTION_THRESHOLD
from agents.llm.ollama_client import OllamaClient
from agents.llm.prompts import PromptTemplates


class ReflectionSystem:
    """
    Generates reflections (higher-level insights) from observations.

    From the Stanford paper:
    "Reflections are higher-level, more abstract thoughts generated by
    the agent. Reflections are generated periodically when the sum of
    importance scores of recent observations exceeds a threshold."

    The reflection process:
    1. Identify when to reflect (importance threshold)
    2. Generate questions about recent observations
    3. Use those questions to generate insights
    4. Store insights with citations back to source memories
    """

    # Prompt for generating reflection questions
    QUESTION_PROMPT = """Given only the information below, what are 3 most salient high-level questions we can answer about the subjects in the statements?

Statements about {agent_name}:
{statements}

Respond with exactly 3 questions, one per line, numbered 1-3.
Questions:
1."""

    # Prompt for generating insights
    INSIGHT_PROMPT = """Statements about {agent_name}:
{numbered_statements}

What 5 high-level insights can you infer from the above statements? Format each insight with the statement numbers that support it.

Example format:
1. Insight text here (because of 1, 5, 3)

Insights:
1."""

    def __init__(
        self,
        agent_id: UUID,
        agent_name: str,
        memory_stream: MemoryStream,
        ollama_client: Optional[OllamaClient] = None,
        reflection_threshold: float = REFLECTION_THRESHOLD,
    ):
        """
        Initialize reflection system.

        Args:
            agent_id: Agent's UUID
            agent_name: Agent's name for prompts
            memory_stream: Agent's memory stream
            ollama_client: LLM client for generation
            reflection_threshold: Importance sum to trigger reflection
        """
        self.agent_id = agent_id
        self.agent_name = agent_name
        self.memory_stream = memory_stream
        self.client = ollama_client
        self.threshold = reflection_threshold

        self._last_reflection: Optional[datetime] = None

    def should_reflect(self) -> bool:
        """
        Check if agent should generate reflections.

        Returns:
            True if importance threshold exceeded
        """
        return self.memory_stream.should_reflect()

    def get_importance_sum(self) -> float:
        """Get current accumulated importance"""
        return self.memory_stream.get_importance_sum()

    async def reflect(
        self,
        force: bool = False,
        num_insights: int = 5
    ) -> List[Reflection]:
        """
        Generate reflections from recent observations.

        Args:
            force: Force reflection even if threshold not met
            num_insights: Number of insights to generate

        Returns:
            List of generated reflections
        """
        if not force and not self.should_reflect():
            return []

        # Get recent observations
        observations = await self.memory_stream.retrieve_recent(
            hours=24,
            memory_types=[MemoryType.OBSERVATION]
        )

        if len(observations) < 3:
            return []  # Need at least a few observations

        # Generate questions about observations
        questions = await self._generate_questions(observations[:20])

        # Generate insights
        insights = await self._generate_insights(observations[:20], questions)

        # Store reflections
        reflections = []
        for insight_text, source_indices in insights:
            # Get source memory IDs
            source_ids = [
                observations[i].memory_id
                for i in source_indices
                if i < len(observations)
            ]

            reflection = await self.memory_stream.add_reflection(
                description=insight_text,
                source_memories=source_ids,
                importance=0.8  # Reflections are high importance
            )
            reflections.append(reflection)

        self._last_reflection = datetime.utcnow()
        return reflections

    async def reflect_on_topic(
        self,
        topic: str,
        num_insights: int = 3
    ) -> List[Reflection]:
        """
        Generate reflections about a specific topic.

        Args:
            topic: Topic to reflect on
            num_insights: Number of insights

        Returns:
            Generated reflections
        """
        # Retrieve memories about the topic
        memories = await self.memory_stream.retrieve(
            query=topic,
            limit=20,
            alpha_relevance=2.0  # Weight relevance heavily
        )

        if len(memories) < 3:
            return []

        # Generate insights
        insights = await self._generate_insights(memories, [f"What do I know about {topic}?"])

        reflections = []
        for insight_text, source_indices in insights[:num_insights]:
            source_ids = [
                memories[i].memory_id
                for i in source_indices
                if i < len(memories)
            ]

            reflection = await self.memory_stream.add_reflection(
                description=insight_text,
                source_memories=source_ids,
                importance=0.75
            )
            reflections.append(reflection)

        return reflections

    async def reflect_on_agent(
        self,
        other_agent_name: str
    ) -> List[Reflection]:
        """
        Generate reflections about another agent.

        Args:
            other_agent_name: Name of the other agent

        Returns:
            Generated reflections
        """
        return await self.reflect_on_topic(other_agent_name)

    async def _generate_questions(
        self,
        observations: List[Memory]
    ) -> List[str]:
        """
        Generate salient questions from observations.

        Args:
            observations: Recent observations

        Returns:
            List of questions
        """
        if not self.client:
            # Fallback: generate generic questions
            return self._heuristic_questions(observations)

        # Format observations as statements
        statements = "\n".join(
            f"- {obs.description}"
            for obs in observations[:15]
        )

        prompt = self.QUESTION_PROMPT.format(
            agent_name=self.agent_name,
            statements=statements
        )

        try:
            response = await self.client.generate(
                prompt=prompt,
                temperature=0.7,
                max_tokens=200
            )

            # Parse questions from response
            questions = self._parse_questions(response.text)
            return questions if questions else self._heuristic_questions(observations)

        except Exception:
            return self._heuristic_questions(observations)

    async def _generate_insights(
        self,
        observations: List[Memory],
        questions: List[str]
    ) -> List[tuple]:
        """
        Generate insights from observations.

        Args:
            observations: Observations to analyze
            questions: Guiding questions

        Returns:
            List of (insight_text, source_indices) tuples
        """
        if not self.client:
            return self._heuristic_insights(observations)

        # Format as numbered statements
        numbered = "\n".join(
            f"{i+1}. {obs.description}"
            for i, obs in enumerate(observations[:15])
        )

        prompt = self.INSIGHT_PROMPT.format(
            agent_name=self.agent_name,
            numbered_statements=numbered
        )

        try:
            response = await self.client.generate(
                prompt=prompt,
                temperature=0.8,
                max_tokens=500
            )

            # Parse insights with citations
            insights = self._parse_insights(response.text)
            return insights if insights else self._heuristic_insights(observations)

        except Exception:
            return self._heuristic_insights(observations)

    def _parse_questions(self, response: str) -> List[str]:
        """Parse questions from LLM response"""
        questions = []
        lines = response.strip().split('\n')

        for line in lines:
            # Remove numbering and clean up
            line = re.sub(r'^\d+[\.\)]\s*', '', line.strip())
            if line and '?' in line:
                questions.append(line)

        return questions[:3]

    def _parse_insights(self, response: str) -> List[tuple]:
        """
        Parse insights with citations from LLM response.

        Returns list of (insight_text, source_indices)
        """
        insights = []
        lines = response.strip().split('\n')

        for line in lines:
            if not line.strip():
                continue

            # Remove numbering
            line = re.sub(r'^\d+[\.\)]\s*', '', line.strip())

            # Extract citations (because of 1, 5, 3)
            citation_match = re.search(r'\(because of ([0-9,\s]+)\)', line)
            sources = []

            if citation_match:
                citation_str = citation_match.group(1)
                sources = [
                    int(n.strip()) - 1  # Convert to 0-indexed
                    for n in citation_str.split(',')
                    if n.strip().isdigit()
                ]
                # Remove citation from insight text
                insight_text = line[:citation_match.start()].strip()
            else:
                insight_text = line.strip()

            if insight_text and len(insight_text) > 10:
                insights.append((insight_text, sources))

        return insights[:5]

    def _heuristic_questions(self, observations: List[Memory]) -> List[str]:
        """Generate questions using heuristics"""
        questions = []

        # Check for patterns
        has_social = any('met' in o.description.lower() or 'talked' in o.description.lower()
                        for o in observations)
        has_work = any('made' in o.description.lower() or 'worked' in o.description.lower()
                      for o in observations)
        has_travel = any('went' in o.description.lower() or 'traveled' in o.description.lower()
                        for o in observations)

        if has_social:
            questions.append(f"What social interactions has {self.agent_name} had recently?")
        if has_work:
            questions.append(f"What has {self.agent_name} been working on?")
        if has_travel:
            questions.append(f"Where has {self.agent_name} been going?")

        if not questions:
            questions.append(f"What has been important to {self.agent_name} lately?")

        return questions[:3]

    def _heuristic_insights(self, observations: List[Memory]) -> List[tuple]:
        """Generate insights using heuristics"""
        insights = []

        # Count patterns
        social_obs = [i for i, o in enumerate(observations)
                     if 'met' in o.description.lower() or 'talked' in o.description.lower()]
        work_obs = [i for i, o in enumerate(observations)
                   if 'made' in o.description.lower() or 'crafted' in o.description.lower()]

        if len(social_obs) >= 2:
            insights.append((
                f"{self.agent_name} has been socially active lately.",
                social_obs[:3]
            ))

        if len(work_obs) >= 2:
            insights.append((
                f"{self.agent_name} has been productive and working hard.",
                work_obs[:3]
            ))

        if len(observations) >= 5:
            insights.append((
                f"{self.agent_name} has had many experiences recently.",
                list(range(min(3, len(observations))))
            ))

        return insights


class ReflectionTrigger:
    """
    Monitors when reflection should occur.
    """

    def __init__(
        self,
        threshold: float = REFLECTION_THRESHOLD,
        min_interval_hours: float = 1.0
    ):
        """
        Initialize trigger.

        Args:
            threshold: Importance sum threshold
            min_interval_hours: Minimum hours between reflections
        """
        self.threshold = threshold
        self.min_interval = timedelta(hours=min_interval_hours)
        self._last_trigger: Optional[datetime] = None
        self._accumulated_importance: float = 0.0

    def add_observation(self, importance: float) -> bool:
        """
        Add observation importance and check if should trigger.

        Args:
            importance: Importance of new observation (0-1)

        Returns:
            True if reflection should trigger
        """
        # Scale to 1-10 like paper
        self._accumulated_importance += importance * 10

        if self._accumulated_importance >= self.threshold:
            if self._can_trigger():
                return True

        return False

    def trigger(self) -> None:
        """Mark that reflection was triggered"""
        self._last_trigger = datetime.utcnow()
        self._accumulated_importance = 0.0

    def _can_trigger(self) -> bool:
        """Check if enough time has passed since last trigger"""
        if self._last_trigger is None:
            return True
        return datetime.utcnow() - self._last_trigger >= self.min_interval

    def get_accumulated(self) -> float:
        """Get accumulated importance"""
        return self._accumulated_importance

    def reset(self) -> None:
        """Reset accumulated importance"""
        self._accumulated_importance = 0.0
